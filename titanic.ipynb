{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ca77a7-9254-47be-a0da-acca0334029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73083980-7fe7-4708-b019-3cd4585d39c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ced812-bcbf-42d9-ac86-7e3d53185998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female    0.742038\n",
       "male      0.188908\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(\"Sex\")[\"Survived\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2967431-5646-4b31-b422-a3f381449253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    0.629630\n",
       "2    0.472826\n",
       "3    0.242363\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(\"Pclass\")[\"Survived\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cb3d4aa-65b9-4e7b-85cc-2cd4c70c66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set copy\n",
    "predictions = test.copy()\n",
    "# Predict 1 (survived) if female, 0 (died) if male\n",
    "predictions[\"Survived\"] = predictions[\"Sex\"].map(lambda x: 1 if x == \"female\" else 0)\n",
    "# PassengerId and Survived for submission\n",
    "submissions = predictions[[\"PassengerId\", \"Survived\"]]\n",
    "submissions.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee5fc0f6-380a-407b-8a8e-96c766586cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select features\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "X = train[features].copy()\n",
    "y = train[\"Survived\"].copy()\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "X[\"Age\"] = X[\"Age\"].fillna(X[\"Age\"].median())\n",
    "X[\"Embarked\"] = X[\"Embarked\"].fillna(X[\"Embarked\"].mode()[0])\n",
    "\n",
    "# Step 3: Convert categorical text into numbers\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Step 4: Prepare the test set in the same way\n",
    "X_test = test[features].copy()\n",
    "X_test[\"Age\"] = X_test[\"Age\"].fillna(X_test[\"Age\"].median())\n",
    "X_test[\"Fare\"] = X_test[\"Fare\"].fillna(X_test[\"Fare\"].median())\n",
    "X_test[\"Embarked\"] = X_test[\"Embarked\"].fillna(X_test[\"Embarked\"].mode()[0])\n",
    "X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c73d62f-f5ef-46ef-86a1-1101a3ec46f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a528322-fc74-4b7a-b19d-fdb1c13e12ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Accuracy: 0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "print(\"Random Forest Validation Accuracy:\", accuracy_score(y_val, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "921a74df-ab2c-4e97-9eaf-15476e94f069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with FamilySize Accuracy: 0.8212290502793296\n"
     ]
    }
   ],
   "source": [
    "# Create a new feature: family size\n",
    "X[\"FamilySize\"] = X[\"SibSp\"] + X[\"Parch\"] + 1  # +1 to include the passenger themselves\n",
    "\n",
    "# Rerun the split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Retrain Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "print(\"Random Forest with FamilySize Accuracy:\", accuracy_score(y_val, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3e1a83b-2453-4778-94f6-02f2cce5c678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\faizs\\AppData\\Local\\Temp\\ipykernel_9500\\4240152083.py:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  train[\"Title\"] = train[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n",
      "C:\\Users\\faizs\\AppData\\Local\\Temp\\ipykernel_9500\\4240152083.py:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  test[\"Title\"] = test[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n",
      "C:\\Users\\faizs\\AppData\\Local\\Temp\\ipykernel_9500\\4240152083.py:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  train[\"Title\"] = train[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n",
      "C:\\Users\\faizs\\AppData\\Local\\Temp\\ipykernel_9500\\4240152083.py:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  test[\"Title\"] = test[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['FamilySize'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Add Title into features\u001b[39;00m\n\u001b[0;32m     15\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSibSp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFamilySize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 17\u001b[0m X \u001b[38;5;241m=\u001b[39m train[features]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     18\u001b[0m y \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Fill missing values again (now including Title)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['FamilySize'] not in index\""
     ]
    }
   ],
   "source": [
    "# Extract Title from Name\n",
    "train[\"Title\"] = train[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n",
    "test[\"Title\"] = test[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n",
    "\n",
    "# Simplify rare titles into a single category\n",
    "rare_titles = [\"Dr\", \"Col\", \"Major\", \"Rev\", \"Jonkheer\", \"Capt\", \"Don\", \"Sir\", \"the Countess\", \"Lady\"]\n",
    "train[\"Title\"] = train[\"Title\"].replace(rare_titles, \"Rare\")\n",
    "test[\"Title\"] = test[\"Title\"].replace(rare_titles, \"Rare\")\n",
    "\n",
    "# Group similar ones\n",
    "train[\"Title\"] = train[\"Title\"].replace({\"Mlle\": \"Miss\", \"Ms\": \"Miss\", \"Mme\": \"Mrs\"})\n",
    "test[\"Title\"] = test[\"Title\"].replace({\"Mlle\": \"Miss\", \"Ms\": \"Miss\", \"Mme\": \"Mrs\"})\n",
    "\n",
    "# Add Title into features\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\"]\n",
    "\n",
    "X = train[features].copy()\n",
    "y = train[\"Survived\"].copy()\n",
    "\n",
    "# Fill missing values again (now including Title)\n",
    "X[\"Age\"] = X[\"Age\"].fillna(X[\"Age\"].median())\n",
    "X[\"Embarked\"] = X[\"Embarked\"].fillna(X[\"Embarked\"].mode()[0])\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X_test = test[features].copy()\n",
    "X_test[\"Age\"] = X_test[\"Age\"].fillna(X_test[\"Age\"].median())\n",
    "X_test[\"Fare\"] = X_test[\"Fare\"].fillna(X_test[\"Fare\"].median())\n",
    "X_test[\"Embarked\"] = X_test[\"Embarked\"].fillna(X_test[\"Embarked\"].mode()[0])\n",
    "X_test = pd.get_dummies(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ba6c27f-8487-46b5-a3a5-d1fe5873b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure FamilySize is created in both train and test\n",
    "train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n",
    "test[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1\n",
    "\n",
    "# Extract Title (with raw string r\"...\")\n",
    "train[\"Title\"] = train[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\", expand=False)\n",
    "test[\"Title\"] = test[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\", expand=False)\n",
    "\n",
    "# Simplify rare titles\n",
    "rare_titles = [\"Dr\", \"Col\", \"Major\", \"Rev\", \"Jonkheer\", \"Capt\", \"Don\", \"Sir\", \"the Countess\", \"Lady\"]\n",
    "train[\"Title\"] = train[\"Title\"].replace(rare_titles, \"Rare\")\n",
    "test[\"Title\"] = test[\"Title\"].replace(rare_titles, \"Rare\")\n",
    "\n",
    "# Merge similar titles\n",
    "train[\"Title\"] = train[\"Title\"].replace({\"Mlle\": \"Miss\", \"Ms\": \"Miss\", \"Mme\": \"Mrs\"})\n",
    "test[\"Title\"] = test[\"Title\"].replace({\"Mlle\": \"Miss\", \"Ms\": \"Miss\", \"Mme\": \"Mrs\"})\n",
    "\n",
    "# Define features (now including both FamilySize and Title)\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\"]\n",
    "\n",
    "# Build X and y\n",
    "X = train[features].copy()\n",
    "y = train[\"Survived\"].copy()\n",
    "\n",
    "# Handle missing values\n",
    "X[\"Age\"] = X[\"Age\"].fillna(X[\"Age\"].median())\n",
    "X[\"Embarked\"] = X[\"Embarked\"].fillna(X[\"Embarked\"].mode()[0])\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X_test = test[features].copy()\n",
    "X_test[\"Age\"] = X_test[\"Age\"].fillna(X_test[\"Age\"].median())\n",
    "X_test[\"Fare\"] = X_test[\"Fare\"].fillna(X_test[\"Fare\"].median())\n",
    "X_test[\"Embarked\"] = X_test[\"Embarked\"].fillna(X_test[\"Embarked\"].mode()[0])\n",
    "X_test = pd.get_dummies(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "feb45844-b04e-4d25-b06c-f2e72b460015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RF (200 trees) Validation Accuracy: 0.8212290502793296\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Grid search best cross-val score: 0.8370\n",
      "Best params: {'max_depth': 6, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best RF Validation Accuracy: 0.8324022346368715\n",
      "\n",
      "Top 10 feature importances:\n",
      "Title_Mr              0.1830\n",
      "Sex_female            0.1411\n",
      "Sex_male              0.1238\n",
      "Fare                  0.1114\n",
      "Pclass                0.1027\n",
      "Age                   0.0701\n",
      "FamilySize            0.0671\n",
      "Title_Mrs             0.0514\n",
      "SibSp                 0.0377\n",
      "Title_Miss            0.0350\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Align train/test columns after get_dummies\n",
    "X_test = X_test.reindex(columns = X.columns, fill_value=0)\n",
    "\n",
    "# Split (same as before)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Baseline stronger RF (just to check quickly)\n",
    "rf_baseline = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "pred_baseline = rf_baseline.predict(X_val)\n",
    "print(\"Baseline RF (200 trees) Validation Accuracy:\", accuracy_score(y_val, pred_baseline))\n",
    "\n",
    "# Small Grid Search for better hyperparameters (lightweight)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"max_depth\": [4, 6, 8, None],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid = GridSearchCV(rf, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nGrid search best cross-val score: {:.4f}\".format(grid.best_score_))\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "\n",
    "# Evaluate best model on validation set\n",
    "best_rf = grid.best_estimator_\n",
    "y_pred = best_rf.predict(X_val)\n",
    "print(\"Best RF Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# Feature importances (top 10)\n",
    "importances = best_rf.feature_importances_\n",
    "feat_names = X.columns\n",
    "imp_df = list(zip(feat_names, importances))\n",
    "imp_df = sorted(imp_df, key=lambda x: x[1], reverse=True)[:10]\n",
    "print(\"\\nTop 10 feature importances:\")\n",
    "for fname, imp in imp_df:\n",
    "    print(f\"{fname:20s}  {imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3a0d971-e6e5-4262-b9b8-0251f99e0bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv created! You can now upload it to Kaggle.\n"
     ]
    }
   ],
   "source": [
    "# Predict survival on the test set\n",
    "test_predictions = best_rf.predict(X_test)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Survived\": test_predictions\n",
    "})\n",
    "\n",
    "# Save as CSV (ready to upload to Kaggle)\n",
    "submission.to_csv(\"faiz_submission.csv\", index=False)\n",
    "\n",
    "print(\"submission.csv created! You can now upload it to Kaggle.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9188d05e-a9c0-444e-8ea0-12bdeedbddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"IsAlone\"] = (train[\"FamilySize\"] == 1).astype(int)\n",
    "test[\"IsAlone\"] = (test[\"FamilySize\"] == 1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff5ef7b2-0da8-464e-9eac-dcb9bf5218f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Deck\"] = train[\"Cabin\"].str[0].fillna(\"U\")  # U = Unknown\n",
    "test[\"Deck\"] = test[\"Cabin\"].str[0].fillna(\"U\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25246553-9896-43af-a920-040fb866b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \n",
    "            \"FamilySize\", \"Title\", \"IsAlone\", \"Deck\"]\n",
    "\n",
    "# Recreate X and X_test with these features\n",
    "X = train[features].copy()\n",
    "y = train[\"Survived\"].copy()\n",
    "\n",
    "X[\"Age\"] = X[\"Age\"].fillna(X[\"Age\"].median())\n",
    "X[\"Fare\"] = X[\"Fare\"].fillna(X[\"Fare\"].median())\n",
    "X[\"Embarked\"] = X[\"Embarked\"].fillna(X[\"Embarked\"].mode()[0])\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X_test = test[features].copy()\n",
    "X_test[\"Age\"] = X_test[\"Age\"].fillna(X_test[\"Age\"].median())\n",
    "X_test[\"Fare\"] = X_test[\"Fare\"].fillna(X_test[\"Fare\"].median())\n",
    "X_test[\"Embarked\"] = X_test[\"Embarked\"].fillna(X_test[\"Embarked\"].mode()[0])\n",
    "X_test = pd.get_dummies(X_test)\n",
    "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6772173-4e85-444e-917d-ee70afe4abdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved submission.csv created!\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=42)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Predict on test set\n",
    "predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Create final submission\n",
    "submission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": predictions})\n",
    "submission.to_csv(\"faiz_submission.csv\", index=False)\n",
    "print(\"Improved submission.csv created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ca6c1-b002-465b-9d8d-c1fa71ccea12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
